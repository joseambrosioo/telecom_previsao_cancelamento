# app.py

import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.figure_factory as ff
from dash import Dash, dcc, html, Input, Output
import dash_bootstrap_components as dbc
import joblib
import os
from sklearn.metrics import (
    accuracy_score,
    recall_score,
    precision_score,
    f1_score,
    roc_auc_score,
    cohen_kappa_score,
    confusion_matrix,
    roc_curve,
)

# Importa√ß√£o dos Modelos (necess√°rio para carregar as classes)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import (
    RandomForestClassifier,
    GradientBoostingClassifier,
    AdaBoostClassifier,
    BaggingClassifier,
)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.discriminant_analysis import (
    LinearDiscriminantAnalysis,
    QuadraticDiscriminantAnalysis,
)
from sklearn.neural_network import MLPClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler

# --- Carregamento de Dados e Objetos Pr√©-treinados ---
# Carregar os transformadores e a lista de colunas da pasta 'data'
try:
    std = joblib.load('data/scaler.pkl')
    le = joblib.load('data/label_encoder.pkl')
    cols = joblib.load('data/features.pkl')
except FileNotFoundError:
    print("Erro: Arquivos de pr√©-processamento n√£o encontrados. Certifique-se de ter executado 'train_models.py' primeiro.")
    exit()

# Carregar os dados brutos e aplicar o pr√©-processamento salvo
telcom = pd.read_csv('dataset/churn-bigml-80.csv')
telcom_test = pd.read_csv('dataset/churn-bigml-20.csv')
    
def preprocess_data_for_app(df):
    """Aplica as transforma√ß√µes salvas nos dados brutos."""
    col_to_drop = [
        'State', 'Area code', 'Total day charge', 'Total eve charge',
        'Total night charge', 'Total intl charge'
    ]
    df = df.drop(columns=col_to_drop, axis=1)

    bin_cols = [col for col in df.columns if df[col].nunique() == 2 and col != 'Churn']
    for col in bin_cols:
        df[col] = le.transform(df[col])

    num_cols = [col for col in df.columns if df[col].dtype in ['float64', 'int64'] and col not in bin_cols + ['Churn']]
    df[num_cols] = std.transform(df[num_cols])
    return df

telcom = preprocess_data_for_app(telcom)
telcom_test = preprocess_data_for_app(telcom_test)

# Separar os dados para avalia√ß√£o
y_test = telcom[['Churn']]
X_test = telcom[cols]

# --- Carregar os Modelos Treinados ---
print("Carregando modelos treinados...")
model_results = {}
try:
    for filename in os.listdir('models'):
        if filename.endswith('.pkl'):
            # Transforma o nome do arquivo para o formato de exibi√ß√£o
            model_name = filename.replace('.pkl', '').replace('_', ' ')
            model_results[model_name] = joblib.load(f'models/{filename}')
    print("Modelos carregados com sucesso!")
except FileNotFoundError:
    print("Erro: Pasta 'models' n√£o encontrada. Certifique-se de ter executado 'train_models.py' primeiro.")
    exit()

# --- Defini√ß√£o das M√©tricas ---
def get_metrics_df(X, y):
    df_rows = []
    for name, model in model_results.items():
        predictions = model.predict(X)
        try:
            probabilities = model.predict_proba(X)[:, 1]
            roc_auc = roc_auc_score(y, probabilities)
        except (AttributeError, IndexError):
            roc_auc = "N/A"
        
        df_rows.append({
            'Modelo': name,
            'Acur√°cia': accuracy_score(y, predictions),
            'Revoca√ß√£o': recall_score(y, predictions, zero_division=0),
            'Precis√£o': precision_score(y, predictions, zero_division=0),
            'F1-Score': f1_score(y, predictions, zero_division=0),
            'ROC-AUC': roc_auc,
            'Kappa': cohen_kappa_score(y, predictions),
        })
    return pd.DataFrame(df_rows).round(4)

metrics_train = get_metrics_df(X_test, y_test)
metrics_test = get_metrics_df(telcom_test[cols], telcom_test[['Churn']])

# --- Layout do Painel ---
app = Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])
server = app.server

header = dbc.Navbar(
    dbc.Container(
        [
            html.Div(
                [
                    html.Span("‚òéÔ∏è", className="me-2"),
                    dbc.NavbarBrand("Previs√£o de Cancelamento (Churn) de Clientes de Telecom", class_name="fw-bold text-wrap", style={"color": "black"}),
                ], className="d-flex align-items-center"
            ),
            dbc.Badge("Dashboard", color="primary", className="ms-auto")
        ]
    ),
    color="light",
    class_name="shadow-sm mb-3"
)

# 1. Aba ASK
ask_tab = dcc.Markdown(
    """
    ### ‚ùì **ASK** ‚Äî A Vis√£o Geral
    Esta se√ß√£o define o prop√≥sito do projeto e seu valor para o neg√≥cio.

    **Tarefa de Neg√≥cio**: O objetivo √© prever quais clientes s√£o propensos a parar de usar nosso servi√ßo, um processo conhecido como **churn de clientes**. Para as empresas de telecomunica√ß√µes, manter os clientes existentes √© muito mais barato do que encontrar novos. Ao prever o churn, podemos entrar em contato proativamente com clientes em risco e tentar reconquist√°-los.

    **Partes Interessadas**: Os principais tomadores de decis√£o que usar√£o este painel s√£o **Marketing** e **Servi√ßo ao Cliente**. Eles precisam dessas informa√ß√µes para planejar campanhas direcionadas e estrat√©gias de reten√ß√£o. A lideran√ßa executiva tamb√©m se beneficia de uma vis√£o de alto n√≠vel de nossos esfor√ßos de reten√ß√£o de clientes.

    **Entreg√°veis**: O produto final √© este dashboard, que oferece um passo a passo claro de nossa an√°lise e apresenta as principais descobertas e recomenda√ß√µes.
    """, className="p-4"
)

# 2. Aba PREPARE
prepare_tab = html.Div(
    children=[
        html.H4(
            ["üìù ", html.B("PREPARE"), " ‚Äî Preparando os Dados"],
            className="mt-4"
        ),
        html.P("Antes de podermos construir um modelo preditivo, precisamos entender e limpar nossos dados."),
        html.H5("Fonte de Dados"),
        html.P(
            ["Usamos um conjunto de dados padr√£o de churn de telecom, dividido em um ", html.B("conjunto de treinamento"), " (80% dos dados) para construir nossos modelos e um ", html.B("conjunto de teste"), " separado (20%) para verificar se nossos modelos funcionam em novos dados, nunca vistos."]
        ),
        dbc.Row(
            [
                dbc.Col(
                    dbc.Card(
                        [
                            dbc.CardHeader("Conjunto de Dados de Treinamento"),
                            dbc.CardBody(
                                [
                                    html.P(f"Linhas: {telcom.shape[0]}"),
                                    html.P(f"Caracter√≠sticas: {telcom.shape[1]}"),
                                ]
                            ),
                        ], className="mb-3"
                    )
                ),
                dbc.Col(
                    dbc.Card(
                        [
                            dbc.CardHeader("Conjunto de Dados de Teste"),
                            dbc.CardBody(
                                [
                                    html.P(f"Linhas: {telcom_test.shape[0]}"),
                                    html.P(f"Caracter√≠sticas: {telcom_test.shape[1]}"),
                                ]
                            ),
                        ], className="mb-3"
                    )
                ),
            ]
        ),
        html.H4("Resumo Estat√≠stico", className="mt-4"),
        html.P("Esta tabela fornece uma vis√£o geral estat√≠stica r√°pida das caracter√≠sticas. Note a rela√ß√£o linear perfeita entre minutos e cobran√ßas para diferentes tipos de chamada. Para evitar multicolinearidade em nossos modelos, removemos as colunas relacionadas a cobran√ßas."),
        dbc.Table.from_dataframe(telcom.describe().T.reset_index().rename(columns={'index': 'caracter√≠stica'}).round(2),
                                 striped=True, bordered=True, hover=True),
    ], className="p-4"
)

# 3. Aba ANALYZE com sub-abas
analyze_tab = html.Div(
    children=[
        html.H4(
            ["üìà ", html.B("ANALYZE"), " ‚Äî Encontrando Padr√µes e Construindo Modelos"],
            className="mt-4"
        ),
        html.P("Aqui √© onde exploramos os dados e constru√≠mos o c√©rebro preditivo do nosso painel."),
        dbc.Tabs([
            dbc.Tab(label="An√°lise Explorat√≥ria de Dados", children=[
                html.Div(
                    children=[
                        html.H5("Distribui√ß√£o e Correla√ß√µes do Churn", className="mt-4"),
                        html.P(
                            ["O gr√°fico de pizza abaixo mostra que nossos dados est√£o ", html.B("desbalanceados"), "‚Äîuma pequena porcentagem de clientes cancelou. Isso √© importante porque significa que um modelo simples poderia obter uma alta pontua√ß√£o de acur√°cia apenas prevendo que ningu√©m nunca cancelar√°. √â por isso que precisamos de m√©tricas de avalia√ß√£o mais avan√ßadas."]
                        ),
                        dbc.Row([
                            dbc.Col(dcc.Graph(id="churn-pie-chart",
                                             figure=go.Figure(
                                                 data=[go.Pie(labels=telcom["Churn"].value_counts().keys().tolist(),
                                                              values=telcom["Churn"].value_counts().values.tolist(),
                                                              marker=dict(colors=['#1f77b4', '#ff7f0e'], line=dict(color="white", width=1.3)),
                                                              hoverinfo="label+percent", hole=0.5)],
                                                 layout=go.Layout(title="Distribui√ß√£o de Churn de Clientes", height=400, margin=dict(t=50, b=50))
                                             )), md=6),
                            dbc.Col(dcc.Graph(id="correlation-matrix"), md=6),
                        ]),
                        html.P(
                            ["A ", html.B("Matriz de Correla√ß√£o"), " √† direita mostra o qu√£o fortemente cada caracter√≠stica se relaciona com as outras. Uma cor escura indica uma rela√ß√£o forte. A principal conclus√£o √© que caracter√≠sticas como minutos de chamada e chamadas para o servi√ßo de atendimento ao cliente est√£o correlacionadas com o churn, o que confirma nossa intui√ß√£o."]
                        ),
                        html.H5("Visualiza√ß√£o das Caracter√≠sticas", className="mt-4"),
                        html.P("Este gr√°fico visualiza os dados usando duas caracter√≠sticas chave: total de minutos diurnos e total de minutos noturnos. Separamos esses per√≠odos porque o comportamento do cliente e os motivos para o churn podem ser diferentes ao longo do dia. Um cliente que faz muitas chamadas longas durante o dia pode ser um usu√°rio de neg√≥cios, enquanto um cliente com chamadas noturnas longas pode ser um usu√°rio familiar. Esses diferentes comportamentos podem ter diferentes raz√µes para o churn. Um modelo que olha apenas o total de minutos n√£o capturaria essas nuances."),
                        dbc.Row([
                            dbc.Col(dcc.Graph(
                                id="day-eve-minutes-plot",
                                figure=go.Figure(
                                    data=go.Scatter(x=telcom['Total day minutes'], y=telcom['Total eve minutes'],
                                                     mode='markers', marker_color=telcom['Churn'], showlegend=False),
                                    layout=go.Layout(title="Total de Minutos Diurnos vs. Total de Minutos Noturnos",
                                                     xaxis_title="Total de Minutos Diurnos (Escalado)",
                                                     yaxis_title="Total de Minutos Noturnos (Escalado)",
                                                     height=400, margin=dict(t=50, b=50))
                                ))),
                        ]),
                    ], className="p-4"
                )
            ]),
            dbc.Tab(label="Desempenho do Modelo (Treinamento)", children=[
                html.Div(
                    children=[
                        html.H5("Desempenho do Modelo nos Dados de Treinamento", className="mt-4"),
                        html.P("Treinamos uma variedade de modelos de aprendizado de m√°quina para ver qual deles tem o melhor desempenho."),
                        html.P(
                            ["‚Ä¢ ", html.B("O Problema com a Acur√°cia"), ": Para nossos dados desbalanceados, a ", html.B("Acur√°cia"), " (a porcentagem de previs√µes corretas) n√£o √© a melhor m√©trica. Um modelo que sempre prev√™ 'sem churn' poderia ter 85% de acur√°cia, mas seria in√∫til para identificar clientes em risco."]
                        ),
                        html.P(
                            ["‚Ä¢ ", html.B("M√©tricas Chave"), ": Focamos em um conjunto mais completo de m√©tricas: ", html.B("Revoca√ß√£o"), " (quantos clientes que cancelaram n√≥s pegamos?), ", html.B("Precis√£o"), " (daqueles que marcamos como churners, quantos estavam corretos?), ", html.B("F1-Score"), " (um equil√≠brio de ambos), e ", html.B("ROC-AUC"), " (o qu√£o bem o modelo separa os clientes que cancelam dos que n√£o cancelam)."]
                        ),
                        dbc.Row([dbc.Col(dcc.Graph(id="train-metrics-bar"), md=12)]),
                        html.P(
                            ["Nossa an√°lise mostra que ", html.B("LightGBM"), " e ", html.B("XGBoost"), ", ambos tipos de modelos avan√ßados baseados em √°rvores, superaram significativamente os outros. Eles alcan√ßaram altas pontua√ß√µes em todas as m√©tricas, provando que s√£o excelentes na identifica√ß√£o do churn."]
                        ),
                        dbc.Row([
                            dbc.Col(dcc.Graph(id="train-confusion-matrix"), md=6),
                            dbc.Col(dcc.Graph(id="train-roc-curve"), md=6),
                        ]),
                        html.H5("Import√¢ncia das Caracter√≠sticas (para modelos baseados em √°rvores)", className="mt-4"),
                        html.P("Este gr√°fico classifica as caracter√≠sticas com base em quanto elas contribu√≠ram para a previs√£o do modelo. As duas caracter√≠sticas mais importantes foram `Total day minutes` e `International plan`. Isso nos d√° um ponto de partida claro para nossas recomenda√ß√µes."),
                        dcc.Dropdown(
                            id="feature-importance-model",
                            options=[{'label': name, 'value': name} for name in ['√Årvore de Decis√£o', 'Random Forest', 'Classificador LGBM', 'Classificador XGBoost', 'Gradient Boosting']],
                            value='Classificador LGBM'
                        ),
                        dcc.Graph(id="feature-importance-plot"),
                    ], className="p-4"
                )
            ]),
            dbc.Tab(label="Desempenho do Modelo (Teste)", children=[
                html.Div(
                    children=[
                        html.H5("Desempenho do Modelo nos Dados de Teste", className="mt-4"),
                        html.P(
                            ["Testamos nossos principais modelos nos dados n√£o vistos para garantir que n√£o est√£o com ", html.B("overfitting"), " (memorizando os dados de treinamento em vez de aprender padr√µes gerais). O desempenho permaneceu alto, confirmando que os modelos s√£o confi√°veis e funcionar√£o bem em um cen√°rio real."]
                        ),
                        dbc.Row([dbc.Col(dcc.Graph(id="test-metrics-bar"), md=12)]),
                        html.P(
                            ["O desempenho nos dados de teste √© semelhante ao dos dados de treinamento, confirmando que o ", html.B("Classificador LGBM"), " e o ", html.B("Classificador XGBoost"), " s√£o excelentes escolhas para este problema. Suas altas pontua√ß√µes de ", html.B("F1-Score"), " e ", html.B("ROC-AUC"), " em ambos os conjuntos de dados indicam uma capacidade preditiva forte e confi√°vel."]
                        ),
                        dbc.Row([
                            dbc.Col(dcc.Graph(id="test-confusion-matrix"), md=6),
                            dbc.Col(dcc.Graph(id="test-roc-curve"), md=6),
                        ]),
                        html.P("O desempenho consistente desses modelos no conjunto de teste √© uma descoberta chave. Sugere que um sistema preditivo pode ser constru√≠do para identificar clientes em risco de churn com alta confian√ßa."),
                    ], className="p-4"
                )
            ]),
        ])
    ]
)

# 4. Aba ACT
act_tab = dcc.Markdown(
    """
    ### üöÄ **ACT** ‚Äî O que Fazer em Seguida
    Esta √© a se√ß√£o mais importante, pois traduz os insights dos dados em uma estrat√©gia de neg√≥cio.

    -   **Direcionar Clientes de Alto Risco**: Os modelos identificaram que clientes com um **plano internacional** e alto **total de minutos diurnos** s√£o os mais propensos a cancelar. Este √© o grupo perfeito para uma campanha de marketing direcionada.
    -   **Reten√ß√£o Proativa**: Em vez de esperar que os clientes cancelem, a empresa deve usar o modelo implantado para obter uma lista di√°ria de clientes com alto risco de churn. Um representante de servi√ßo ao cliente pode ent√£o ligar para eles proativamente para oferecer um desconto, uma atualiza√ß√£o de servi√ßo, ou simplesmente para verificar sua satisfa√ß√£o.
    -   **Implantar o Melhor Modelo**: O **Classificador LightGBM** √© nosso modelo recomendado para implanta√ß√£o devido ao seu desempenho superior nos dados de treinamento e teste. Este modelo ser√° o c√©rebro por tr√°s de nossa nova estrat√©gia proativa de redu√ß√£o de churn.
    """, className="p-4"
)

app.layout = dbc.Container(
    [
        header,
        dbc.Tabs(
            [
                dbc.Tab(ask_tab, label="Perguntar"),
                dbc.Tab(prepare_tab, label="Preparar"),
                dbc.Tab(analyze_tab, label="Analisar"),
                dbc.Tab(act_tab, label="Agir"),
            ]
        ),
    ],
    fluid=True,
)

# --- Callbacks ---
@app.callback(
    Output("correlation-matrix", "figure"),
    Input("churn-pie-chart", "id") # Entrada fict√≠cia para acionar no carregamento
)
def update_corr_matrix(dummy):
    correlation = telcom.corr()
    fig = ff.create_annotated_heatmap(
        z=correlation.values.round(2),
        x=list(correlation.columns),
        y=list(correlation.index),
        colorscale="Viridis",
        showscale=True,
        reversescale=True
    )
    fig.update_layout(title="Matriz de Correla√ß√£o", height=500, margin=dict(t=50, b=50))
    return fig

@app.callback(
    Output("train-metrics-bar", "figure"),
    Output("test-metrics-bar", "figure"),
    Output("train-confusion-matrix", "figure"),
    Output("test-confusion-matrix", "figure"),
    Output("train-roc-curve", "figure"),
    Output("test-roc-curve", "figure"),
    Input('feature-importance-model', 'value')
)
def update_model_performance(selected_model):
    def get_bar_chart(df, title):
        fig = go.Figure()
        for metric in ['Acur√°cia', 'Revoca√ß√£o', 'Precis√£o', 'F1-Score', 'ROC-AUC', 'Kappa']:
            fig.add_trace(go.Bar(
                y=df["Modelo"],
                x=df[metric],
                orientation='h',
                name=metric
            ))
        fig.update_layout(
            barmode='group',
            title=title,
            height=450,
            margin=dict(l=150, r=20, t=50, b=20),
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        return fig

    train_bar_chart = get_bar_chart(metrics_train, "M√©tricas do Modelo (Dados de Treinamento)")
    test_bar_chart = get_bar_chart(metrics_test, "M√©tricas do Modelo (Dados de Teste)")

    model = model_results.get(selected_model, model_results['Classificador LGBM'])

    y_pred_train = model.predict(X_test)
    cm_train = confusion_matrix(y_test, y_pred_train)
    fig_cm_train = ff.create_annotated_heatmap(
        z=cm_train, x=["N√£o Churn", "Churn"], y=["N√£o Churn", "Churn"],
        colorscale='blues'
    )
    fig_cm_train.update_layout(title=f"Matriz de Confus√£o ({selected_model} no Treinamento)", height=450, margin=dict(t=50, b=50))

    y_pred_test = model.predict(telcom_test[cols])
    cm_test = confusion_matrix(telcom_test['Churn'], y_pred_test)
    fig_cm_test = ff.create_annotated_heatmap(
        z=cm_test, x=["N√£o Churn", "Churn"], y=["N√£o Churn", "Churn"],
        colorscale='blues'
    )
    fig_cm_test.update_layout(title=f"Matriz de Confus√£o ({selected_model} no Teste)", height=450, margin=dict(t=50, b=50))

    def get_roc_curve(model, X, y, title):
        if hasattr(model, "predict_proba"):
            probabilities = model.predict_proba(X)[:, 1]
            fpr, tpr, _ = roc_curve(y, probabilities)
            fig = go.Figure(data=[
                go.Scatter(x=fpr, y=tpr, mode='lines', name='Curva ROC'),
                go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash'), name='Chute Aleat√≥rio')
            ])
            fig.update_layout(
                title=title,
                xaxis_title="Taxa de Falso Positivo",
                yaxis_title="Taxa de Verdadeiro Positivo",
                height=450,
                margin=dict(t=50, b=50)
            )
        else:
            fig = go.Figure(go.Scatter())
            fig.update_layout(title=f"Curva ROC N√£o Dispon√≠vel para {selected_model}", height=450, margin=dict(t=50, b=50))
        return fig

    roc_train = get_roc_curve(model, X_test, y_test, f"Curva ROC ({selected_model} no Treinamento)")
    roc_test = get_roc_curve(model, telcom_test[cols], telcom_test['Churn'], f"Curva ROC ({selected_model} no Teste)")

    return (
        train_bar_chart,
        test_bar_chart,
        fig_cm_train,
        fig_cm_test,
        roc_train,
        roc_test,
    )

@app.callback(
    Output("feature-importance-plot", "figure"),
    Input("feature-importance-model", "value")
)
def update_feature_importance(selected_model):
    model = model_results.get(selected_model)
    
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
        feature_names = cols
        df_importance = pd.DataFrame({
            'caracter√≠stica': feature_names,
            'import√¢ncia': importances
        }).sort_values(by='import√¢ncia', ascending=False)
        
        fig = go.Figure(go.Bar(
            x=df_importance['import√¢ncia'],
            y=df_importance['caracter√≠stica'],
            orientation='h'
        ))
        fig.update_layout(
            title=f"Import√¢ncia das Caracter√≠sticas para {selected_model}",
            xaxis_title="Import√¢ncia",
            yaxis_title="Caracter√≠stica",
            height=500,
            margin=dict(l=150, t=50, b=50)
        )
        return fig
    else:
        fig = go.Figure(go.Scatter())
        fig.update_layout(title=f"Import√¢ncia das Caracter√≠sticas N√£o Dispon√≠vel para {selected_model}", height=450, margin=dict(t=50, b=50))
        return fig

if __name__ == "__main__":
    app.run(debug=True)